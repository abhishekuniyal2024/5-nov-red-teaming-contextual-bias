## this project is created on 5 nov 2025. 'detoxify + nlp' approach did not work as expected. now i am moving to contextual_bias approach.
- i will have to deliver this project by tuesday 11-nov.
- set temp to 0 and random_seed fix 0. so answer will most likely remain same. 

## **installation guide:**
- create env: python3.10 -m venv venv
- activate env: source venv/bin/activate
- install library: pip install -r requirements.txt

- do it if only if it gave error during sentence-transformers, other wise dont do it: pip install --upgrade pip setuptools wheel

---

## **TO DO LIST**

- fine tune the llm. select which one i need to do or should i do all 3 llm.
- chatgpt asnwer: Fine-tune LLaMA (or another open model) using your bias-corrected or bias-balanced dataset.
  Use the other two (Gemini and GPT) only as comparative benchmarks — not fine-tuning targets.

| Goal                                   | Best Strategy                 |
| -------------------------------------- | ----------------------------- |
| Show “before vs after” bias mitigation | ✅ **Use Wrapper Approach**   |
| Long-term bias correction (own model)  | Optional LoRA fine-tune later |
| Quick deployment / demo                | Wrapper → CSV → visualization |

- Your wrapper adds ~1× the LLM’s latency per rewrite.
  On Groq: LLaMA-4-Maverick (400B): ~10–14 s per full round.
         Gemma-1B: ~2 s per full round.

- On your hardware, only Gemma (≤ 3 B) can run locally.
- The wrapper approach remains efficient — cost is purely the double API call, not local compute.


- ask tl what spacy library version i should install. spacy earlier gave lots of issue.
# Load SpaCy NLP model safely
try:
    import spacy
    nlp = spacy.load("en_core_web_sm")
except (ImportError, OSError):
    logging.info("Installing SpaCy model en_core_web_sm ...")
    subprocess.run([
        sys.executable, "-m", "pip", "install",
        "https://github.com/explosion/spacy-models/releases/download/"
        "en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl"
    ], check=True)
    import spacy
    nlp = spacy.load("en_core_web_sm")

keep this in requiremnets.txt file: spacy==3.8.0
https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl

---

## **core files**

- **dataset/ dataset.json:** new data which has 2 option for each prompt. new created data is based on race, gender, intersectional.

- **dataset_response/ dataset_response.csv:** response created by milestone1_gen_output.py. on this data i will run my   milestone2_contextual_bias_testing.py

- **bias_analysis_output/ contextual_bias_results.csv:** file generated by milestone2_contextual_bias_analysis.py. it has context_bias scoring.

- **extra files/ :** extra files like client msg, client image, bad dataset response, milestone, response to client.

- **milestone1_gen_output.py:** it will generate response from 3 llm and create new file from it in folder dataset_response.
- **milestone2_*contextual_bias_analysis.py:** it will work on file 'dataset_response.csv' that will be generated from milestone1_gen_output.py to give contextual_bias_results.csv

- **milestone2_alternative.py:** milestone2_contextual_bias_analysis.py is giving same bias scoring for llm even when prompt is slightly changed based on race, gender, and intersectional. trying to fix that issue here.
- **milestone2_alternative1.py** same as milestone2_alternative.py, just change semantic model, weights, normlaization, scaling. this file is working.
- **milestone2_alternative2.py** same as milestone2_alternative1.py, just change it for Sentence-level semantic embeddings 
- **milestone2_alternative3.py** same as milestone2_alternative2.py, Semantic shift is now directional and asymmetric

- **milestone.md**: milestone that i was suppose to follow.
- **client_msg_5nov.md:** client give this msg on 5 nov with a client_image.jpeg file
- **client_image.jpeg:**  image that client gave with client_msg_5nov.md 
- **project_Structure.md:** this is the structure i will follow for this project.

---